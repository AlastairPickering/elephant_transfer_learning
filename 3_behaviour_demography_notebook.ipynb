{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6c385f6",
   "metadata": {},
   "source": [
    "# Forest elephant rumble vocalisation analysis\n",
    "\n",
    "This Jupyter notebook provides a step-by-step guide to using pre-trained CNNs via transfer learning to identify rumble vocalisation sub-types and to identify associations between rumble acoustic features and different contexts (age, sex, behaviour, distress). This builds on the call-types analysis notebook using the main techniques of transfer learning to automatically extract acoustic features and unsupervised ordination of these features into lower dimensional space. \n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "This dataset contains information on African forest elephant vocalisations recorded in Dzanga-Bai clearing, Central African Republic, between September 2018 and April 2019 by the Elephant Listening Project.\n",
    "\n",
    "It includes:\n",
    "\n",
    "1. `elephant_vocalisations.csv`: A table of 1254 annotated vocalisations, each with start time, end time, frequency range, call type (roar, rumble, or trumpet), and corresponding audio file.\n",
    "2. `elephant_contextual_observations.csv`: A table containing 359 entries, each describing the context in which a specific audio recording was made. This includes information about the elephants vocalising (e.g., age, sex, behaviour) and the overall context of the recording (distress).  Importantly, each audio file may contain multiple individual vocalisations, but all the vocalisations within that file share the same contextual information.\n",
    "3. `{model}_vocalisations_features.parquet`: Parquet files storing acoustic features extracted from the vocalisations using the workflow described in the `1_feature_extraction` notebook. Features are extracted using four different CNN models (VGGish, YAMNet, BirdNET, and Perch).\n",
    "\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. **Set-up**: Load the vocalisationa and contextual data, as well as the pre-computed features.\n",
    "2. **Data Filtering and Aggregation**: Select only rumble vocalisations and average the acoustic features across all rumbles within each audio file. This ensures that each data point represents the overall acoustic characteristics of rumbles within a specific context.\n",
    "3. **Dimensionality reduction**: Project the acoustic features into 2D space as the basis for clustering and statistical analysis\n",
    "4. **Unsupervised clustering: rumble sub-type identification**: Use affinity propagation to automatically cluster the rumble features and visually inspect age, sex, behaviour and distress composition of clusters\n",
    "5. **Behavioural and demographic analysis**: Perform statistical tests to assess the signficance of changes in acoustic features and different contexts.\n",
    "\n",
    "**Note:** Feature extraction is a computationally intensive process. \n",
    "To avoid re-computation, this notebook uses pre-computed features. \n",
    "Refer to the `1_feature_extraction_notebook` for details on the feature extraction workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae38caa7-0a4d-4dab-9361-d26e6e08bf7c",
   "metadata": {},
   "source": [
    "### 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7790f344",
   "metadata": {},
   "source": [
    "Here we import all the relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c69abe-34b8-492d-94a8-927de2334354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e9213",
   "metadata": {},
   "source": [
    "Now we load the table containing information about each of the elephant vocalisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37cf93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "OUTPUTS_DIR = Path(\"outputs\")\n",
    "\n",
    "vocalisations = pd.read_csv(DATA_DIR / \"elephant_vocalisations.csv\")\n",
    "context = pd.read_csv(DATA_DIR / \"elephant_contextual_observations.csv\")\n",
    "\n",
    "vocalisations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "780ec8a1-6adc-406d-88e3-40989ec0f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\"VGGish\", \"YAMNet\", \"BirdNET\", \"Perch\"]\n",
    "\n",
    "features = {\n",
    "    model: pd.read_parquet(\n",
    "        OUTPUTS_DIR / f\"{model.lower()}_vocalisation_features.parquet\"\n",
    "    )\n",
    "    for model in MODELS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a20ee28-3be1-4349-b925-d721c12b4919",
   "metadata": {},
   "source": [
    "## 2. Data Filtering and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab82ab2a-bf43-41fe-9000-e3d8f05439da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge contextual information to full vocalisation dataset\n",
    "df = pd.merge(\n",
    "    left=vocalisations,\n",
    "    right=context,\n",
    "    left_on=\"filename\",\n",
    "    right_on=\"filename\",\n",
    ")\n",
    "\n",
    "# We no longer need info about the temporal and spectral span of each vocalisation\n",
    "df = df.drop(columns=[\"start_time\", \"end_time\", \"low_freq\", \"high_freq\", \"duration\"])\n",
    "\n",
    "# Remove files that contain non-rumble vocalisations\n",
    "df = df.groupby(\"filename\").filter(\n",
    "    lambda group: group[\"call_type\"].isin([\"Rumble\"]).all()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42e8a45-4cfa-47bf-a7b9-a1355f9db245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_rumble_features(metadata, features):\n",
    "    # Join the feature table with the metadata table to associate vocalisation features\n",
    "    # to the file in which they appear.\n",
    "    merged = pd.merge(\n",
    "        left=metadata[[\"filename\", \"vocalisation_id\"]],\n",
    "        right=features,\n",
    "        left_on=\"vocalisation_id\",\n",
    "        right_index=True,\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    # Compute the average features of all vocalisations from the same file.\n",
    "    return merged.drop(columns=[\"vocalisation_id\"]).groupby(\"filename\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ef81777-2534-465f-aa7e-00abc28fe041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the aggregated features for all models\n",
    "aggregated = {\n",
    "    model: aggregate_rumble_features(df, feats) for model, feats in features.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e83a9c",
   "metadata": {},
   "source": [
    "### 3. Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff1867a",
   "metadata": {},
   "source": [
    "Now that we have the feature embeddings for each of the 361 recordings we need to reduce this high-dimensional data into lower dimensional space to make it interpretable to the human brain and usable in the statistical tests. This involves 2 steps:\n",
    "1. Normalise the embeddings so that their mean = 0 and variance = 1. This ensures equal weighting of the features\n",
    "2. Carry out the dimensionality reduction with specified parameters, including the number of components (2) and distance metric we want to use (cosine)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b68e366",
   "metadata": {},
   "source": [
    "**Normalisation step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa8f53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Function to normalise the DataFrame\n",
    "def normalise_features(features):\n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform the features\n",
    "    normalised_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Create a new DataFrame for the normalised features\n",
    "    normalised = pd.DataFrame(\n",
    "        normalised_features,\n",
    "        columns=features.columns,\n",
    "        index=features.index,\n",
    "    )\n",
    "\n",
    "    # Return the normalised DataFrame\n",
    "    return normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a3bdaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise aggregated features from all models\n",
    "normalised = {model: normalise_features(agg) for model, agg in aggregated.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3826f15",
   "metadata": {},
   "source": [
    "**Dimensionality reduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c563930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "# Specify the UMAP parameters\n",
    "N_COMP = 2  # select 1, 2 or 3 dimensions\n",
    "METRIC = \"cosine\"  # distance metric used\n",
    "N_NEIGHBORS = 15\n",
    "MIN_DIST = 0\n",
    "RANDOM_STATE = 2204\n",
    "\n",
    "\n",
    "# Function to fit UMAP and merge metadata\n",
    "def process_umap(\n",
    "    normalised_df,\n",
    "    metadata_df,\n",
    "    n_comp=N_COMP,\n",
    "    metric=METRIC,\n",
    "    min_dist=MIN_DIST,\n",
    "    n_neighbors=N_NEIGHBORS,\n",
    "    random_state=RANDOM_STATE,\n",
    "):\n",
    "    # Instantiate UMAP projector with provided parameters\n",
    "    reducer = umap.UMAP(\n",
    "        n_components=N_COMP,\n",
    "        metric=metric,\n",
    "        min_dist=min_dist,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    # Fit UMAP and obtain embeddings\n",
    "    embedding = reducer.fit_transform(normalised_df)\n",
    "\n",
    "    # Create DataFrame with UMAP embeddings, preserving 'vocalisation_id' as index\n",
    "    umap_results = pd.DataFrame(\n",
    "        embedding,\n",
    "        columns=[f\"UMAP{i + 1}\" for i in range(N_COMP)],\n",
    "        index=normalised_df.index,\n",
    "    )\n",
    "\n",
    "    # Merge UMAP coordinates with metadata to obtain the\n",
    "    # corresponding call type\n",
    "    return umap_results.merge(metadata_df, on=\"filename\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project features using UMAP for all models\n",
    "umaps = {model: process_umap(norm, df) for model, norm in normalised.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420cd3a",
   "metadata": {},
   "source": [
    "### 4. Unsupervised Clustering: Rumble Sub-type identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f05481e-abdf-4d41-a708-57ad112ab21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4707db7c",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "random_state = 2204\n",
    "damping = 0.95\n",
    "preference = -90\n",
    "max_iter = 1000\n",
    "N_COMP = 2\n",
    "\n",
    "\n",
    "def affinity_propagation_clustering(\n",
    "    features_standardized,\n",
    "    damping,\n",
    "    preference,\n",
    "    random_state,\n",
    "    max_iter,\n",
    "):\n",
    "    # Perform affinity propagation clustering\n",
    "    affinity_propagation = AffinityPropagation(\n",
    "        damping=damping,\n",
    "        preference=preference,\n",
    "        random_state=random_state,\n",
    "        max_iter=max_iter,\n",
    "    )\n",
    "    cluster_labels = affinity_propagation.fit_predict(features_standardized)\n",
    "    return cluster_labels\n",
    "\n",
    "\n",
    "# Perform affinity propagation clustering and save the new cluster column for each of the 4 UMAP files\n",
    "# Loop through each UMAP DataFrame\n",
    "for umap_name, umap_df in umaps.items():\n",
    "    # Dynamically select the UMAP columns based on N_COMP\n",
    "    umap_columns = [f\"UMAP{i}\" for i in range(1, N_COMP + 1)]\n",
    "    embeddings = umap_df[umap_columns].values\n",
    "\n",
    "    # Perform affinity propagation clustering\n",
    "    cluster_labels = affinity_propagation_clustering(\n",
    "        embeddings,\n",
    "        damping=damping,\n",
    "        preference=preference,\n",
    "        random_state=random_state,\n",
    "        max_iter=max_iter,\n",
    "    )\n",
    "\n",
    "    # Add the 'Cluster' column to the DataFrame\n",
    "    umap_df[\"Cluster\"] = cluster_labels\n",
    "\n",
    "    # Print the updated DataFrame\n",
    "    print(f\"Cluster labels added to {umap_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d3b533",
   "metadata": {},
   "source": [
    "We can visually assess the level of separation achieved by the unsupervised methods but this needs to be accompanied by a statistical analysis of its performance. We will do this by calculating the overall silhouette score for the data and the silhouette score per call-type.\n",
    "\n",
    "The silhouete score is a mathematical representation of the tightness and separation of each cluster (Rousseeuw, 1987). It is calculated as the mean Euclidean distance between data points within a cluster (a) and the mean Euclidean distance to points in the nearest cluster (Rousseeuw, 1987).\n",
    "\n",
    "Typically, silhouette scores >=0.5 show evidence for clustering, while those >=0.7 show strong evidence for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f17a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "# Define a darker version of the colour-blind friendly palette\n",
    "darkened_palette = [\n",
    "    \"#b57600\",  # Darker orange\n",
    "    \"#3d7faf\",  # Darker sky blue\n",
    "    \"#007b5a\",  # Darker bluish green\n",
    "    \"#b2a62d\",  # Darker yellow\n",
    "    \"#005082\",  # Darker blue\n",
    "    \"#a64700\",  # Darker vermillion\n",
    "    \"#a14376\",  # Darker reddish purple\n",
    "    \"#707070\",  # Darker grey\n",
    "]\n",
    "\n",
    "# Define different marker shapes\n",
    "marker_shapes = [\n",
    "    \"o\",\n",
    "    \"s\",\n",
    "    \"D\",\n",
    "    \"^\",\n",
    "    \"P\",\n",
    "    \"X\",\n",
    "    \"*\",\n",
    "    \"v\",\n",
    "]  # circle, square, diamond, triangle, etc.\n",
    "\n",
    "# Set the style of the visualisation\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "\n",
    "# Function to calculate silhouette scores and plot UMAPs or boxplot (depending on N_COMP)\n",
    "def plot_umap_with_silhouette(umap_df, model_name, ax, n_comp):\n",
    "    if n_comp == 1:\n",
    "        # Calculate silhouette scores for the boxplot title\n",
    "        labels = umap_df[\"Cluster\"]\n",
    "        silhouette_avg = silhouette_score(umap_df[[\"UMAP1\"]], labels)\n",
    "\n",
    "        # Create a boxplot if N_COMP is 1\n",
    "        boxplot = sns.boxplot(\n",
    "            x=\"Cluster\", y=\"UMAP1\", data=umap_df, palette=darkened_palette, ax=ax\n",
    "        )\n",
    "        ax.set_title(f\"{model_name} (Silhouette: {silhouette_avg:.2f})\", fontsize=14)\n",
    "        ax.set_xlabel(\"Cluster\", fontsize=12)\n",
    "        ax.set_ylabel(\"UMAP1\", fontsize=12)\n",
    "        ax.tick_params(axis=\"x\", labelsize=12)\n",
    "        ax.tick_params(axis=\"y\", labelsize=12)\n",
    "\n",
    "        # Extend y-axis to make space for the legend\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        ax.set_ylim(ymin - 0.1 * (ymax - ymin), ymax + 0.1 * (ymax - ymin))\n",
    "\n",
    "        # Create a custom legend to show clusters and their respective colours\n",
    "        cluster_legend = []\n",
    "        unique_labels = sorted(umap_df[\"Cluster\"].unique())\n",
    "        for i, label in enumerate(unique_labels):\n",
    "            cluster_legend.append(\n",
    "                mpatches.Patch(color=darkened_palette[i], label=f\"Cluster {label}\")\n",
    "            )\n",
    "\n",
    "        ax.legend(\n",
    "            handles=cluster_legend,\n",
    "            title=\"Clusters\",\n",
    "            title_fontsize=12,\n",
    "            fontsize=10,\n",
    "            loc=\"best\",\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        # Calculate silhouette scores across all data points\n",
    "        labels = umap_df[\"Cluster\"]\n",
    "        silhouette_avg = silhouette_score(umap_df[[\"UMAP1\", \"UMAP2\"]], labels)\n",
    "        silhouette_values = silhouette_samples(umap_df[[\"UMAP1\", \"UMAP2\"]], labels)\n",
    "\n",
    "        # Prepare a dictionary to store average silhouette scores for each label\n",
    "        silhouette_dict = {}\n",
    "        unique_labels = sorted(labels.unique())\n",
    "        for label in unique_labels:\n",
    "            label_indices = labels == label\n",
    "            avg_silhouette_score = silhouette_values[label_indices].mean()\n",
    "            silhouette_dict[label] = avg_silhouette_score\n",
    "\n",
    "        # Scatter plot with different marker shapes for each cluster\n",
    "        for i, label in enumerate(unique_labels):\n",
    "            cluster_data = umap_df[umap_df[\"Cluster\"] == label]\n",
    "            ax.scatter(\n",
    "                x=cluster_data[\"UMAP1\"],\n",
    "                y=cluster_data[\"UMAP2\"],\n",
    "                label=f\"Cluster {label} (Silhouette: {silhouette_dict[label]:.2f})\",\n",
    "                color=darkened_palette[i],\n",
    "                marker=marker_shapes[i % len(marker_shapes)],\n",
    "                s=80,  # Increased marker size\n",
    "                alpha=0.8,  # Slight transparency for better visual contrast\n",
    "            )\n",
    "\n",
    "        # Extend x and y axes to make space for the legend\n",
    "        xmin, xmax = ax.get_xlim()\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        ax.set_xlim(xmin - 0.1 * (xmax - xmin), xmax + 0.1 * (xmax - xmin))\n",
    "        ax.set_ylim(ymin - 0.1 * (ymax - ymin), ymax + 0.1 * (ymax - ymin))\n",
    "\n",
    "        # Set the title, labels, parameters\n",
    "        ax.set_title(f\"{model_name} (Silhouette: {silhouette_avg:.2f})\", fontsize=14)\n",
    "        ax.set_xlabel(\"UMAP1\", fontsize=12)\n",
    "        ax.set_ylabel(\"UMAP2\", fontsize=12)\n",
    "        ax.tick_params(axis=\"x\", labelsize=12)\n",
    "        ax.tick_params(axis=\"y\", labelsize=12)\n",
    "\n",
    "        # Custom legend for clusters\n",
    "        ax.legend(title=\"Cluster\", title_fontsize=12, fontsize=10, loc=\"best\")\n",
    "\n",
    "\n",
    "# Example of plotting all 4 models' UMAPs in a 2x2 grid\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 20), dpi=300)\n",
    "\n",
    "# Replace these dataframes with your actual dataframes\n",
    "plot_umap_with_silhouette(umaps[\"VGGish\"], \"VGGish\", axs[0, 0], n_comp=N_COMP)\n",
    "plot_umap_with_silhouette(umaps[\"Perch\"], \"Perch\", axs[0, 1], n_comp=N_COMP)\n",
    "plot_umap_with_silhouette(umaps[\"YAMNet\"], \"YAMNet\", axs[1, 0], n_comp=N_COMP)\n",
    "plot_umap_with_silhouette(umaps[\"BirdNET\"], \"BirdNET\", axs[1, 1], n_comp=N_COMP)\n",
    "\n",
    "# Adjust layout for a clean 2x2 grid\n",
    "plt.tight_layout(pad=4.0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc9fb0",
   "metadata": {},
   "source": [
    "**Visual inspection of rumble sub-types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac755b",
   "metadata": {},
   "source": [
    "Plot column charts of the unsupervised clusters split by their Age, Sex, Distress and Behaviour labels to identify patterns in the cluster composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c164b6",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Set the seaborn style and color palette\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Define the variables to be plotted\n",
    "variables = [\"Age\", \"Sex\", \"Behaviour\", \"Distress\"]\n",
    "\n",
    "# Define custom titles for each variable\n",
    "titles = [\"Age\", \"Sex\", \"Behaviour\", \"Distress\"]\n",
    "\n",
    "# Specify the order of models to display on the 2x2 grid\n",
    "model_order = [\"VGGish\", \"Perch\", \"YAMNet\", \"BirdNET\"]  #\n",
    "\n",
    "# Loop through each variable and create the 2x2 grid of subplots\n",
    "for i, (variable, title) in enumerate(zip(variables, titles)):\n",
    "    # Set up the figure and axes for the 2x2 grid\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10), dpi=300)\n",
    "\n",
    "    # To store unique handles and labels for a single legend\n",
    "    unique_handles_labels = []\n",
    "\n",
    "    # Loop through each model in the specified order\n",
    "    for j, model_name in enumerate(model_order):\n",
    "        umap_df = umaps[model_name]  # Access the UMAP DataFrame based on the model name\n",
    "        df_filtered = umap_df.copy()  # Make a copy of the DataFrame\n",
    "\n",
    "        # Modify 'Distress' to group 'Unknown' and 'Not Applicable' into 'Other'\n",
    "        if variable == \"Distress\":\n",
    "            df_filtered[variable] = df_filtered[variable].replace(\n",
    "                [\"Unknown\", \"Not Applicable\"], \"Other\"\n",
    "            )\n",
    "\n",
    "        # Exclude 'Anti-Predator' and 'Sexual' levels for the 'Behaviour' variable\n",
    "        if variable == \"Behaviour\":\n",
    "            df_filtered = df_filtered[\n",
    "                (df_filtered[variable] != \"Anti-Predator\")\n",
    "                & (df_filtered[variable] != \"Sexual\")\n",
    "                & (df_filtered[variable] != \"Unknown\")\n",
    "            ]\n",
    "\n",
    "        # Exclude 'Unknown' values for other variables\n",
    "        if variable in [\"Age\", \"Sex\"]:\n",
    "            df_filtered = df_filtered[df_filtered[variable] != \"Unknown\"]\n",
    "\n",
    "        # Calculate counts for each category in the variable, grouped by Cluster\n",
    "        counts = df_filtered.groupby([\"Cluster\", variable]).size().unstack().fillna(0)\n",
    "\n",
    "        # Calculate proportions\n",
    "        proportions = counts.div(counts.sum(axis=0), axis=1) * 100\n",
    "\n",
    "        # Plot the bar chart in the corresponding subplot for each model\n",
    "        ax = proportions.plot(\n",
    "            kind=\"bar\", stacked=False, ax=axes[j // 2, j % 2], legend=False\n",
    "        )\n",
    "        ax.set_title(f\"{model_name} - {title}\", fontsize=12)\n",
    "        ax.set_xlabel(\"Cluster\")\n",
    "        ax.set_ylabel(\"Proportion of category per cluster (%)\")\n",
    "\n",
    "        # Collect unique legend handles and labels for the categories\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        for handle, label in zip(handles, labels):\n",
    "            if label not in [lbl for _, lbl in unique_handles_labels]:\n",
    "                unique_handles_labels.append((handle, label))\n",
    "\n",
    "        # Rotate cluster labels to be horizontal\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "\n",
    "    # Add one shared legend for all subplots with unique categories only\n",
    "    if unique_handles_labels:\n",
    "        handles, labels = zip(*unique_handles_labels)\n",
    "        fig.legend(\n",
    "            handles,\n",
    "            labels,\n",
    "            bbox_to_anchor=(1.01, 0.5),  # Move legend closer to the plots\n",
    "            loc=\"center left\",\n",
    "            title=\"Category\",\n",
    "            fontsize=10,\n",
    "            title_fontsize=12,\n",
    "            borderaxespad=0.5,  # Reduce padding between legend and axes\n",
    "        )\n",
    "\n",
    "    # Adjust layout for better spacing and make room for legend\n",
    "    plt.tight_layout(\n",
    "        rect=[0, 0, 0.99, 1], pad=1.0\n",
    "    )  # Shrink white space between plots and legend\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f700be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seaborn style and color palette\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Define the UMAP DataFrame for the Perch model\n",
    "perch_df = umaps[\"YAMNet\"]\n",
    "\n",
    "# Define the variables to be plotted and their titles\n",
    "variables = [\"Age\", \"Sex\", \"Behaviour\", \"Distress\"]\n",
    "titles = [\"Age\", \"Sex\", \"Behaviour\", \"Distress\"]\n",
    "\n",
    "# Set up the figure and axes for the 2x2 grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8), dpi=900)\n",
    "\n",
    "# Loop through each variable and create subplots for each one\n",
    "for i, (variable, title) in enumerate(zip(variables, titles)):\n",
    "    ax = axes[i // 2, i % 2]  # Get the appropriate subplot\n",
    "\n",
    "    df_filtered = perch_df.copy()  # Make a copy of the Perch DataFrame\n",
    "\n",
    "    # Modify 'Distress' to group 'Unknown' and 'Not Applicable' into 'Other'\n",
    "    if variable == \"Distress\":\n",
    "        df_filtered[variable] = df_filtered[variable].replace(\n",
    "            [\"Unknown\", \"Not Applicable\"], \"Other\"\n",
    "        )\n",
    "\n",
    "    # Exclude 'Anti-Predator' and 'Sexual' levels for the 'Behaviour' variable\n",
    "    if variable == \"Behaviour\":\n",
    "        df_filtered = df_filtered[\n",
    "            (df_filtered[variable] != \"Anti-Predator\")\n",
    "            & (df_filtered[variable] != \"Sexual\")\n",
    "            & (df_filtered[variable] != \"Unknown\")\n",
    "        ]\n",
    "\n",
    "    # Exclude 'Unknown' values for other variables\n",
    "    if variable in [\"Age\", \"Sex\"]:\n",
    "        df_filtered = df_filtered[df_filtered[variable] != \"Unknown\"]\n",
    "\n",
    "    # Calculate counts for each category in the variable, grouped by Cluster\n",
    "    counts = df_filtered.groupby([\"Cluster\", variable]).size().unstack().fillna(0)\n",
    "\n",
    "    # Calculate proportions\n",
    "    proportions = counts.div(counts.sum(axis=0), axis=1) * 100\n",
    "\n",
    "    # Plot the bar chart in the corresponding subplot\n",
    "    proportions.plot(kind=\"bar\", stacked=False, ax=ax)\n",
    "    ax.set_title(f\"YAMNet - {title}\")\n",
    "    ax.set_xlabel(\"Cluster\")\n",
    "    ax.set_ylabel(\"Proportion of category per cluster (%)\")\n",
    "\n",
    "    # Remove 'Unknown' and 'Anti-Predator' from the legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    filtered_handles_labels = [\n",
    "        (h, l)\n",
    "        for h, l in zip(handles, labels)\n",
    "        if l not in [\"Unknown\", \"Anti-Predator\", \"Sexual\"]\n",
    "    ]\n",
    "    if filtered_handles_labels:\n",
    "        handles, labels = zip(*filtered_handles_labels)\n",
    "        ax.legend(\n",
    "            handles,\n",
    "            labels,\n",
    "            bbox_to_anchor=(1.05, 1),\n",
    "            loc=\"upper left\",\n",
    "            title=\"Category\",\n",
    "        )\n",
    "    else:\n",
    "        ax.legend().remove()\n",
    "\n",
    "    # Rotate cluster labels to be horizontal\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "\n",
    "# Adjust layout for better spacing between subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fb5556",
   "metadata": {},
   "source": [
    "## 5. Behavioural and Demographic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23775191",
   "metadata": {},
   "source": [
    "Here we specify and run a Generalised Linear Model to test the statistical significance of the different categories (Age, Sex, Behaviour and Distress) on the UMAP-ordinated acoustic embeddings from each model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a231fee",
   "metadata": {},
   "source": [
    "**Calculate model performance metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import chi2\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    root_mean_squared_error,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to fit GLM and get category-level significance\n",
    "def fit_glm_and_get_category_significance(df):\n",
    "    full_formula = 'UMAP_factor ~ C(Behaviour, Treatment(\"Separation\")) + C(Distress, Treatment(\"No distress\")) + C(Age) + C(Sex)'\n",
    "    full_model = sm.GLM.from_formula(\n",
    "        full_formula,\n",
    "        family=sm.families.Gaussian(sm.families.links.Identity()),\n",
    "        data=df,\n",
    "    ).fit()\n",
    "\n",
    "    category_p_values = {}\n",
    "    for category in [\"Behaviour\", \"Distress\", \"Age\", \"Sex\"]:\n",
    "        reduced_formula = \"UMAP_factor ~ \" + \" + \".join(\n",
    "            [\n",
    "                (\n",
    "                    f'C({cat}, Treatment(\"Separation\"))'\n",
    "                    if cat == \"Behaviour\"\n",
    "                    else (\n",
    "                        f'C({cat}, Treatment(\"No distress\"))'\n",
    "                        if cat == \"Distress\"\n",
    "                        else f\"C({cat})\"\n",
    "                    )\n",
    "                )\n",
    "                for cat in [\"Behaviour\", \"Distress\", \"Age\", \"Sex\"]\n",
    "                if cat != category\n",
    "            ]\n",
    "        )\n",
    "        reduced_model = sm.GLM.from_formula(\n",
    "            reduced_formula,\n",
    "            family=sm.families.Gaussian(sm.families.links.Identity()),\n",
    "            data=df,\n",
    "        ).fit()\n",
    "\n",
    "        lr_stat = 2 * (full_model.llf - reduced_model.llf)\n",
    "        p_value = chi2.sf(lr_stat, df=full_model.df_model - reduced_model.df_model)\n",
    "        category_p_values[category] = p_value\n",
    "\n",
    "    return full_model, category_p_values\n",
    "\n",
    "\n",
    "# Function to analyse model performance\n",
    "def analyze_model_performance(df, glm_result):\n",
    "    actual_values = df[\"UMAP_factor\"]\n",
    "    predicted_values = glm_result.fittedvalues\n",
    "\n",
    "    # Align indices to avoid shape mismatches\n",
    "    actual_values, predicted_values = actual_values.align(\n",
    "        predicted_values, join=\"inner\"\n",
    "    )\n",
    "\n",
    "    mae = mean_absolute_error(actual_values, predicted_values)\n",
    "    rmse = root_mean_squared_error(actual_values, predicted_values)\n",
    "    r2 = r2_score(actual_values, predicted_values)\n",
    "    nrmse = rmse / (max(df[\"UMAP_factor\"]) - min(df[\"UMAP_factor\"]))\n",
    "\n",
    "    return mae, rmse, r2, nrmse\n",
    "\n",
    "\n",
    "# Format and export results\n",
    "def format_and_export_results(final_results, filename):\n",
    "    def format_p_value(p):\n",
    "        if p < 0.001:\n",
    "            return f\"{p:.4f}***\"\n",
    "        elif p < 0.01:\n",
    "            return f\"{p:.4f}**\"\n",
    "        elif p < 0.05:\n",
    "            return f\"{p:.4f}*\"\n",
    "        else:\n",
    "            return f\"{p:.4f}\"\n",
    "\n",
    "    final_results[[\"MAE\", \"RMSE\", \"R2\", \"NRMSE\"]] = final_results[\n",
    "        [\"MAE\", \"RMSE\", \"R2\", \"NRMSE\"]\n",
    "    ].map(lambda x: f\"{x:.4f}\")\n",
    "    for col in [\"Age\", \"Sex\", \"Behaviour\", \"Distress\"]:\n",
    "        if col in final_results.columns:\n",
    "            final_results[col] = final_results[col].apply(format_p_value)\n",
    "    final_results.to_csv(filename)\n",
    "    print(f\"Exported results to {filename}\")\n",
    "\n",
    "\n",
    "# Main Execution\n",
    "cat_vars = [\"Age\", \"Sex\", \"Behaviour\", \"Distress\"]\n",
    "dimensionality_reduction_method = \"PCA\"\n",
    "results = {}\n",
    "category_p_values = {}\n",
    "filtered_dfs = {}\n",
    "\n",
    "# Preprocess and store filtered data once for all analysis\n",
    "for model_name, umap_df in umaps.items():\n",
    "    filtered_df = umap_df.copy()\n",
    "    filtered_df[\"Distress\"] = filtered_df[\"Distress\"].replace(\n",
    "        [\"Unknown\", \"Not Applicable\"], \"Other\"\n",
    "    )\n",
    "    filtered_df = filtered_df[\n",
    "        (filtered_df[\"Behaviour\"] != \"Unknown\")\n",
    "        & (filtered_df[\"Behaviour\"] != \"Sexual\")\n",
    "        & (filtered_df[\"Behaviour\"] != \"Anti-Predator\")\n",
    "        & (filtered_df[\"Age\"] != \"Unknown\")\n",
    "        & (filtered_df[\"Sex\"] != \"Unknown\")\n",
    "    ]\n",
    "    filtered_df[cat_vars] = filtered_df[cat_vars].astype(\"category\")\n",
    "\n",
    "    umap_columns = [f\"UMAP{i}\" for i in range(1, N_COMP + 1)]\n",
    "\n",
    "    if N_COMP == 1:\n",
    "        filtered_df[\"UMAP_factor\"] = filtered_df[\"UMAP1\"]\n",
    "    else:\n",
    "        if dimensionality_reduction_method == \"PCA\":\n",
    "            pca = PCA(n_components=N_COMP)\n",
    "            filtered_df[\"UMAP_factor\"] = pca.fit_transform(filtered_df[umap_columns])[\n",
    "                :, 0\n",
    "            ]\n",
    "        elif dimensionality_reduction_method == \"FA\":\n",
    "            fa = FactorAnalysis(n_components=N_COMP)\n",
    "            filtered_df[\"UMAP_factor\"] = fa.fit_transform(filtered_df[umap_columns])[\n",
    "                :, 0\n",
    "            ]\n",
    "        elif dimensionality_reduction_method == \"CCA\":\n",
    "            cca = CCA(n_components=N_COMP)\n",
    "            cca.fit(filtered_df[umap_columns], filtered_df[umap_columns])\n",
    "            filtered_df[\"UMAP_factor\"] = cca.transform(filtered_df[umap_columns])[:, 0]\n",
    "\n",
    "    filtered_dfs[model_name] = filtered_df\n",
    "\n",
    "# GLM fitting and performance analysis using preprocessed data\n",
    "for model_name, filtered_df in filtered_dfs.items():\n",
    "    glm_result, cat_p_values = fit_glm_and_get_category_significance(filtered_df)\n",
    "    mae, rmse, r2, nrmse = analyze_model_performance(filtered_df, glm_result)\n",
    "\n",
    "    results[model_name] = {\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2,\n",
    "        \"NRMSE\": nrmse,\n",
    "        \"glm_result\": glm_result,\n",
    "    }\n",
    "    category_p_values[model_name] = cat_p_values\n",
    "\n",
    "# Combine performance metrics and category-level significance into a DataFrame\n",
    "performance_results = pd.DataFrame(results).T[[\"MAE\", \"RMSE\", \"R2\", \"NRMSE\"]]\n",
    "category_significance = pd.DataFrame(category_p_values).T\n",
    "final_results = pd.concat([performance_results, category_significance], axis=1)\n",
    "final_results.index.name = \"Model\"\n",
    "\n",
    "# Export results to CSV\n",
    "format_and_export_results(\n",
    "    final_results,\n",
    "    OUTPUTS_DIR / \"glm_category_performance_metrics.csv\",\n",
    ")\n",
    "\n",
    "# Display final results\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739e11f4",
   "metadata": {},
   "source": [
    "**Calculate GLM coefficients per model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2673bd",
   "metadata": {},
   "source": [
    "Next we extract the GLM coefficients for each level for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c037f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format coefficients, standard errors, and p-values\n",
    "def format_coefficients_table(details):\n",
    "    def format_p_value(p):\n",
    "        if p < 0.001:\n",
    "            return f\"{p:.4f}***\"\n",
    "        elif p < 0.01:\n",
    "            return f\"{p:.4f}**\"\n",
    "        elif p < 0.05:\n",
    "            return f\"{p:.4f}*\"\n",
    "        else:\n",
    "            return f\"{p:.4f}\"\n",
    "\n",
    "    details[\"Coefficient\"] = details[\"Coefficient\"].apply(lambda x: f\"{x:.4f}\")\n",
    "    details[\"Std Error\"] = details[\"Std Error\"].apply(lambda x: f\"{x:.4f}\")\n",
    "    details[\"P-Value\"] = details[\"P-Value\"].apply(format_p_value)\n",
    "    return details\n",
    "\n",
    "\n",
    "# Function to extract coefficients, standard errors, and p-values\n",
    "def extract_glm_details(glm_result):\n",
    "    glm_summary = glm_result.summary2().tables[1]\n",
    "    glm_summary = glm_summary[[\"Coef.\", \"Std.Err.\", \"P>|z|\"]]\n",
    "    glm_summary.rename(\n",
    "        columns={\"Coef.\": \"Coefficient\", \"Std.Err.\": \"Std Error\", \"P>|z|\": \"P-Value\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "    return glm_summary\n",
    "\n",
    "\n",
    "# call block\n",
    "model_details = {}\n",
    "\n",
    "for model_name, details in results.items():\n",
    "    # Retrieve the stored GLM result\n",
    "    glm_result = details[\"glm_result\"]\n",
    "\n",
    "    # Extract coefficients, standard errors, and p-values\n",
    "    glm_details = extract_glm_details(glm_result)\n",
    "\n",
    "    # Add model name for later identification and format the table\n",
    "    glm_details[\"Model\"] = model_name\n",
    "    glm_details = format_coefficients_table(glm_details)\n",
    "\n",
    "    model_details[model_name] = glm_details\n",
    "\n",
    "# Combine all models into a single DataFrame and export\n",
    "combined_details = pd.concat(\n",
    "    model_details.values(), keys=model_details.keys(), names=[\"Model\", \"Index\"]\n",
    ")\n",
    "combined_details.to_csv(OUTPUTS_DIR / \"glm_model_coefficients_formatted.csv\")\n",
    "print(\"Exported formatted coefficients to model_coefficients_formatted.csv\")\n",
    "\n",
    "combined_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff5b4db",
   "metadata": {},
   "source": [
    "**Inspect residuals for normality**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d881cd",
   "metadata": {},
   "source": [
    "We validate that the residuals from the GLM do not contravene the assumptions of normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "def plot_residuals_and_qq_for_glms(results, filtered_dfs):\n",
    "    \"\"\"\n",
    "    Generate residual plots and QQ plots for all GLMs, one per model.\n",
    "    Includes:\n",
    "    - Residuals vs Fitted Values\n",
    "    - Histogram of Residuals\n",
    "    - QQ Plot of Residuals\n",
    "    \"\"\"\n",
    "    models = list(results.keys())\n",
    "\n",
    "    for model_name in models:\n",
    "        # Retrieve the GLM result object and corresponding filtered DataFrame\n",
    "        glm_result = results[model_name][\"glm_result\"]  # Extract the fitted GLM object\n",
    "        if glm_result is None:\n",
    "            print(f\"GLM result for {model_name} is missing!\")\n",
    "            continue\n",
    "\n",
    "        filtered_df = filtered_dfs[\n",
    "            model_name\n",
    "        ]  # Use the filtered DataFrame used for fitting\n",
    "\n",
    "        # Extract fitted values and actual values, ensuring alignment to avoid mismatches\n",
    "        fitted_values = glm_result.fittedvalues\n",
    "        actual_values = filtered_df[\"UMAP_factor\"]\n",
    "\n",
    "        # Align indices to ensure no shape mismatch\n",
    "        actual_values, fitted_values = actual_values.align(fitted_values, join=\"inner\")\n",
    "        residuals = actual_values - fitted_values\n",
    "\n",
    "        # Handle case where no residuals can be calculated due to mismatched data\n",
    "        if residuals.empty:\n",
    "            print(f\"No residuals to plot for {model_name} due to mismatched data!\")\n",
    "            continue\n",
    "\n",
    "        # Set up the figure\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "        # 1. Residuals vs Fitted Values\n",
    "        axes[0].scatter(fitted_values, residuals, alpha=0.7, edgecolor=\"k\")\n",
    "        axes[0].axhline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "        axes[0].set_title(f\"Residuals vs Fitted - {model_name}\", fontsize=14)\n",
    "        axes[0].set_xlabel(\"Fitted Values\", fontsize=12)\n",
    "        axes[0].set_ylabel(\"Residuals\", fontsize=12)\n",
    "\n",
    "        # 2. Histogram of Residuals\n",
    "        axes[1].hist(residuals, bins=20, color=\"blue\", alpha=0.7, edgecolor=\"k\")\n",
    "        axes[1].set_title(f\"Residual Histogram - {model_name}\", fontsize=14)\n",
    "        axes[1].set_xlabel(\"Residuals\", fontsize=12)\n",
    "        axes[1].set_ylabel(\"Frequency\", fontsize=12)\n",
    "\n",
    "        # 3. QQ Plot of Residuals\n",
    "        sm.qqplot(residuals, line=\"s\", ax=axes[2])\n",
    "        axes[2].set_title(f\"QQ Plot - {model_name}\", fontsize=14)\n",
    "\n",
    "        # Tidy up and show the plots\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Call the function with updated inputs\n",
    "plot_residuals_and_qq_for_glms(results, filtered_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10c952",
   "metadata": {},
   "source": [
    "**Perform Tukey pairwise analysis of each level in each category**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7a240d",
   "metadata": {},
   "source": [
    "We the run a Tukey Honestly Significantly Different (HSD) pairwise analysis. This enables us to assess which levels (e.g., Adult) in each category (e.g., Age) are signficantly different from other levels (e.g., Infant) within the same category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf22c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# Function to calculate Cohen's d\n",
    "def calculate_cohens_d(group1, group2):\n",
    "    mean_diff = np.mean(group1) - np.mean(group2)\n",
    "    pooled_std = np.sqrt(\n",
    "        (\n",
    "            (len(group1) - 1) * np.var(group1, ddof=1)\n",
    "            + (len(group2) - 1) * np.var(group2, ddof=1)\n",
    "        )\n",
    "        / (len(group1) + len(group2) - 2)\n",
    "    )\n",
    "    return mean_diff / pooled_std\n",
    "\n",
    "\n",
    "# Function to run pairwise Tukey analysis and calculate Cohen's d\n",
    "def run_pairwise_tukey_with_cohens_d(df, var, model_name):\n",
    "    levels = df[var].unique()\n",
    "    combinations = list(itertools.combinations(levels, 2))\n",
    "    tukey_results_all = []\n",
    "\n",
    "    for combo in combinations:\n",
    "        subset_df = df[df[var].isin(combo)]\n",
    "        tukey_results_var = pairwise_tukeyhsd(subset_df[\"UMAP_factor\"], subset_df[var])\n",
    "\n",
    "        # Calculate Cohen's d\n",
    "        group1 = subset_df[subset_df[var] == combo[0]][\"UMAP_factor\"]\n",
    "        group2 = subset_df[subset_df[var] == combo[1]][\"UMAP_factor\"]\n",
    "        cohens_d = calculate_cohens_d(group1, group2)\n",
    "\n",
    "        # Extract the relevant data\n",
    "        for i in range(len(tukey_results_var.reject)):\n",
    "            tukey_results_all.append(\n",
    "                {\n",
    "                    \"Model\": model_name,\n",
    "                    \"Variable\": var,\n",
    "                    \"Level_1\": combo[0],\n",
    "                    \"Level_2\": combo[1],\n",
    "                    \"P-Value\": float(tukey_results_var.pvalues[i]),  # Keep p-value\n",
    "                    \"Cohen_D\": round(cohens_d, 4),  # Add Cohen's d\n",
    "                    \"Reject_Null_Hypothesis\": bool(\n",
    "                        tukey_results_var.reject[i]\n",
    "                    ),  # Track rejection for agreement count\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    tukey_results_df = pd.DataFrame(tukey_results_all)\n",
    "    return tukey_results_df\n",
    "\n",
    "\n",
    "# Function to convert p-value to significance asterisks\n",
    "def p_value_to_stars(p_value):\n",
    "    \"\"\"Convert p-value to asterisks and include the p-value with 4 decimal places.\"\"\"\n",
    "    p_value_rounded = round(p_value, 4)\n",
    "    if p_value < 0.001:\n",
    "        return f\"{p_value_rounded} ***\"\n",
    "    elif p_value < 0.01:\n",
    "        return f\"{p_value_rounded} **\"\n",
    "    elif p_value < 0.05:\n",
    "        return f\"{p_value_rounded} *\"\n",
    "    else:\n",
    "        return f\"{p_value_rounded}\"  # Return just the p-value for non-significant cases\n",
    "\n",
    "\n",
    "# Initialize an empty list to store results across all models\n",
    "all_tukey_results = []\n",
    "\n",
    "# Run pairwise Tukey tests for each variable in each model's DataFrame\n",
    "for model_name, filtered_df in filtered_dfs.items():\n",
    "    # Filter the DataFrame\n",
    "    cat_vars = [\"Age\", \"Sex\", \"Behaviour\", \"Distress\"]\n",
    "    filtered_df[cat_vars] = filtered_df[cat_vars].astype(\"category\")\n",
    "\n",
    "    # Run Tukey analysis for each variable in the current model and append results\n",
    "    for fixed_effect in [\"Behaviour\", \"Distress\", \"Age\", \"Sex\"]:\n",
    "        tukey_results_df = run_pairwise_tukey_with_cohens_d(\n",
    "            filtered_df, fixed_effect, model_name\n",
    "        )\n",
    "        all_tukey_results.append(tukey_results_df)\n",
    "\n",
    "# Concatenate all Tukey results into one DataFrame\n",
    "tukey_all_df = pd.concat(all_tukey_results)\n",
    "\n",
    "# Pivot the results to create a table with significance and Cohen's d for each model\n",
    "p_values_df = tukey_all_df.pivot_table(\n",
    "    index=[\"Level_1\", \"Level_2\", \"Variable\"],\n",
    "    columns=\"Model\",\n",
    "    values=\"P-Value\",\n",
    "    aggfunc=\"first\",\n",
    ")\n",
    "\n",
    "cohen_d_df = tukey_all_df.pivot_table(\n",
    "    index=[\"Level_1\", \"Level_2\", \"Variable\"],\n",
    "    columns=\"Model\",\n",
    "    values=\"Cohen_D\",\n",
    "    aggfunc=\"first\",\n",
    ")\n",
    "\n",
    "# Apply the p-value to asterisks conversion\n",
    "asterisk_df = p_values_df.map(p_value_to_stars)\n",
    "\n",
    "# Merge Cohen's d and p-values with asterisks into the final table\n",
    "final_df = pd.concat(\n",
    "    [asterisk_df.add_suffix(\"_P-Value\"), cohen_d_df.add_suffix(\"_Cohen_D\")], axis=1\n",
    ")\n",
    "\n",
    "# Calculate the Agreement_Count column\n",
    "final_df[\"Agreement_Count\"] = tukey_all_df.pivot_table(\n",
    "    index=[\"Level_1\", \"Level_2\", \"Variable\"],\n",
    "    columns=\"Model\",\n",
    "    values=\"Reject_Null_Hypothesis\",\n",
    "    aggfunc=\"first\",\n",
    ").sum(axis=1)\n",
    "\n",
    "# Reset the index to make the DataFrame more readable\n",
    "final_df.reset_index(inplace=True)\n",
    "\n",
    "# Sort by the Variable column\n",
    "final_df.sort_values(by=\"Variable\", inplace=True)\n",
    "\n",
    "# Optionally, save to CSV for further analysis\n",
    "final_df.to_csv(OUTPUTS_DIR / \"tukey_with_pvalues_and_cohens_d.csv\", index=False)\n",
    "\n",
    "# Display the nicely formatted table\n",
    "table_str = tabulate(final_df, headers=\"keys\", tablefmt=\"pretty\", showindex=False)\n",
    "print(table_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606a58a8",
   "metadata": {},
   "source": [
    "**Present pairwise significance values in bubble chart**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import re\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def plot_bubbles_bigger_labels_spaced(pivot_df):\n",
    "    \"\"\"\n",
    "    Final snippet:\n",
    "      - 5 columns: vggish, perch, yamnet, birdnet, All\n",
    "      - Numeric y-axis, no extra space\n",
    "      - Colour-blind-friendly palette (Okabe & Ito)\n",
    "      - Dashed vertical line at x=3.5\n",
    "      - Bubble saturation by min p-value in the row (lower p => more saturation)\n",
    "      - If bubble_size < 35 => text above bubble in black\n",
    "      - If bubble_size >= 35 and saturation>1.7 => text in bubble, white + bold\n",
    "      - Else text in bubble, black normal\n",
    "    \"\"\"\n",
    "\n",
    "    df = final_df.copy()\n",
    "\n",
    "    # 1) Model columns & names\n",
    "    model_cols = [\n",
    "        \"VGGish_P-Value\",\n",
    "        \"Perch_P-Value\",\n",
    "        \"YAMNet_P-Value\",\n",
    "        \"BirdNET_P-Value\",\n",
    "        \"Agreement_Count\",\n",
    "    ]\n",
    "    model_names = [\"VGGish\", \"Perch\", \"YAMNet\", \"BirdNET\", \"All\"]\n",
    "\n",
    "    # 2) Build \"Comparison\" label\n",
    "    df[\"Comparison\"] = df.apply(lambda r: f\"{r['Level_1']} vs {r['Level_2']}\", axis=1)\n",
    "\n",
    "    # 3) Sort each variable by descending Agreement_Count\n",
    "    var_order = [\"Age\", \"Sex\", \"Behaviour\", \"Distress\"]\n",
    "    df[\"Variable\"] = pd.Categorical(df[\"Variable\"], categories=var_order, ordered=True)\n",
    "    df.sort_values(\n",
    "        by=[\"Variable\", \"Agreement_Count\", \"Level_1\", \"Level_2\"],\n",
    "        ascending=[True, False, True, True],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # Gather final list of comparisons\n",
    "    comp_list = df[\"Comparison\"].unique().tolist()\n",
    "    n_comps = len(comp_list)\n",
    "    # numeric y => top => n_comps-1, bottom => 0\n",
    "    comp_to_y = {comp: (n_comps - 1 - i) for i, comp in enumerate(comp_list)}\n",
    "\n",
    "    # 4) Okabe & Ito colour-blind palette\n",
    "    var_colours = {\n",
    "        \"Age\": \"#009E73\",  # bluish green\n",
    "        \"Sex\": \"#E69F00\",  # orange\n",
    "        \"Behaviour\": \"#0072B2\",  # blue\n",
    "        \"Distress\": \"#D55E00\",  # vermillion\n",
    "    }\n",
    "\n",
    "    def parse_pvalue_and_stars(sig_str):\n",
    "        if not isinstance(sig_str, str) or not sig_str.strip():\n",
    "            return None, \"\"\n",
    "        match = re.search(r\"([\\d.]+)\", sig_str)\n",
    "        p_val = float(match.group(1)) if match else None\n",
    "        if p_val is None:\n",
    "            return None, \"\"\n",
    "\n",
    "        # Assign stars based on the true p-value\n",
    "        if p_val < 0.001:\n",
    "            stars = \"***\"\n",
    "        elif p_val < 0.01:\n",
    "            stars = \"**\"\n",
    "        elif p_val < 0.05:\n",
    "            stars = \"*\"\n",
    "        else:\n",
    "            stars = \"\"\n",
    "\n",
    "        # Return both the original float and a rounded string for display\n",
    "        return p_val, stars\n",
    "\n",
    "    # 6) Convert colour by scaling saturation\n",
    "    def saturate_color(base_hex, sat_factor):\n",
    "        base_hex = base_hex.lstrip(\"#\")\n",
    "        r = int(base_hex[0:2], 16) / 255.0\n",
    "        g = int(base_hex[2:4], 16) / 255.0\n",
    "        b = int(base_hex[4:6], 16) / 255.0\n",
    "        h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "        new_s = max(0.0, min(1.0, s * sat_factor))\n",
    "        r2, g2, b2 = colorsys.hls_to_rgb(h, l, new_s)\n",
    "        return \"#{:02x}{:02x}{:02x}\".format(int(r2 * 255), int(g2 * 255), int(b2 * 255))\n",
    "\n",
    "    # 7) Map p-value -> saturation factor\n",
    "    def saturation_factor_from_pval(p_val):\n",
    "        if p_val is None:\n",
    "            return 0.2\n",
    "        elif p_val < 0.001:\n",
    "            return 5\n",
    "        elif p_val < 0.01:\n",
    "            return 1.5\n",
    "        elif p_val < 0.05:\n",
    "            return 1.2\n",
    "        else:\n",
    "            return 0.35\n",
    "\n",
    "    # 8) Build traces\n",
    "    traces = []\n",
    "    for var in var_order:\n",
    "        sub = df[df[\"Variable\"] == var]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        base_hex = var_colours[var]\n",
    "\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        sizes = []\n",
    "        texts = []\n",
    "        textpos = []\n",
    "        textcols = []\n",
    "        textfamilies = []  # to handle bold vs normal\n",
    "        colorvals = []\n",
    "\n",
    "        for _, row in sub.iterrows():\n",
    "            y_num = comp_to_y[row[\"Comparison\"]]\n",
    "\n",
    "            # min p-value across the 4 significance columns\n",
    "            row_pvals = []\n",
    "            for colm in [\n",
    "                \"VGGish_P-Value\",\n",
    "                \"Perch_P-Value\",\n",
    "                \"YAMNet_P-Value\",\n",
    "                \"BirdNET_P-Value\",\n",
    "            ]:\n",
    "                rp, _ = parse_pvalue_and_stars(\n",
    "                    row[colm] if pd.notnull(row[colm]) else \"\"\n",
    "                )\n",
    "                if rp is not None:\n",
    "                    row_pvals.append(rp)\n",
    "            row_min_p = min(row_pvals) if row_pvals else None\n",
    "            sat_fac = saturation_factor_from_pval(row_min_p)\n",
    "\n",
    "            for mcol, mname in zip(model_cols, model_names):\n",
    "                final_hex = saturate_color(base_hex, sat_fac)\n",
    "\n",
    "                if mcol == \"Agreement_Count\":\n",
    "                    # interpret star_num = min(3, Agreement_Count)\n",
    "                    agr = row[\"Agreement_Count\"]\n",
    "                    star_num = min(3, agr)\n",
    "                    bubble_sz = 22 + star_num * 15\n",
    "                    label_str = str(agr)\n",
    "                else:\n",
    "                    sig_str = row[mcol] if pd.notnull(row[mcol]) else \"\"\n",
    "                    p_val, star_str = parse_pvalue_and_stars(sig_str)\n",
    "                    star_count = len(star_str)\n",
    "\n",
    "                    bubble_sz = 22 + star_count * 15\n",
    "                    if p_val is not None:\n",
    "                        p_val_txt = f\"{p_val:.3f}\"\n",
    "                        label_str = p_val_txt\n",
    "                        if star_str:\n",
    "                            label_str += f\"{star_str}\"\n",
    "                    else:\n",
    "                        label_str = \"n.s.\"\n",
    "\n",
    "                # If bubble_sz < 35 => text above => black normal\n",
    "                if bubble_sz < 37:\n",
    "                    pos = \"top center\"\n",
    "                    txt_colour = \"black\"\n",
    "                    txt_family = \"Arial\"\n",
    "                else:\n",
    "                    # bubble_sz >= 35 => text in bubble\n",
    "                    # if sat_fac>1.7 => white bold\n",
    "                    if sat_fac > 1.7:\n",
    "                        txt_colour = \"white\"\n",
    "                        txt_family = \"Arial Black\"\n",
    "                    else:\n",
    "                        txt_colour = \"black\"\n",
    "                        txt_family = \"Arial\"\n",
    "                    pos = \"middle center\"\n",
    "\n",
    "                x_vals.append(mname)\n",
    "                y_vals.append(y_num)\n",
    "                sizes.append(bubble_sz)\n",
    "                texts.append(label_str)\n",
    "                textpos.append(pos)\n",
    "                textcols.append(txt_colour)\n",
    "                textfamilies.append(txt_family)\n",
    "                colorvals.append(final_hex)\n",
    "\n",
    "        # Build single trace for this variable\n",
    "        trace = go.Scatter(\n",
    "            name=var,\n",
    "            x=x_vals,\n",
    "            y=y_vals,\n",
    "            mode=\"markers+text\",\n",
    "            text=texts,\n",
    "            textposition=textpos,\n",
    "            textfont=dict(\n",
    "                size=14,\n",
    "                color=textcols,\n",
    "                family=\"Arial\",  # single font family across all points in this trace\n",
    "            ),\n",
    "            hoverinfo=\"skip\",\n",
    "            marker=dict(\n",
    "                size=sizes,\n",
    "                color=colorvals,\n",
    "                opacity=0.85,\n",
    "                line=dict(width=1, color=\"white\"),\n",
    "            ),\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "    fig = go.Figure(data=traces)\n",
    "\n",
    "    # X-axis => [0..4]\n",
    "    fig.update_xaxes(\n",
    "        title=\"Model\",\n",
    "        categoryorder=\"array\",\n",
    "        categoryarray=model_names,\n",
    "        tickfont=dict(size=16),  # Increase font size\n",
    "        range=[-0.5, 4.5],\n",
    "    )\n",
    "\n",
    "    # Y-axis => numeric\n",
    "    reversed_labels = comp_list[::-1]\n",
    "    fig.update_yaxes(\n",
    "        title=\"Comparison\",\n",
    "        range=[-0.5, n_comps - 0.5],\n",
    "        tickvals=list(range(n_comps)),\n",
    "        ticktext=reversed_labels,\n",
    "    )\n",
    "\n",
    "    # Dashed line at x=3.5\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        xref=\"x\",\n",
    "        yref=\"paper\",\n",
    "        x0=3.5,\n",
    "        x1=3.5,\n",
    "        y0=0,\n",
    "        y1=1,\n",
    "        line=dict(color=\"gray\", width=2, dash=\"dash\"),\n",
    "    )\n",
    "\n",
    "    # Figure size\n",
    "    fig_width = 900\n",
    "    fig_height = 280 + 70 * n_comps\n",
    "    fig.update_layout(\n",
    "        title=\"Figure 4: Tukey Post-Hoc Pairwise Significance Tests Compared Across CNN Models\",\n",
    "        width=fig_width,\n",
    "        height=fig_height,\n",
    "        showlegend=True,\n",
    "        margin=dict(l=80, r=80, t=90, b=80),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = plot_bubbles_bigger_labels_spaced(final_df)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09070dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "def export_final_chart_to_png(pivot_df, out_file=\"final_chart.png\"):\n",
    "\n",
    "    fig = plot_bubbles_bigger_labels_spaced(pivot_df)\n",
    "    pio.write_image(fig, out_file, width=1000, height=1750, scale=1)  # scale\n",
    "    print(f\"Exported chart to '{out_file}' at ~300 DPI.\")\n",
    "\n",
    "\n",
    "export_final_chart_to_png(final_df, out_file=OUTPUTS_DIR / \"tukey_bubble_revised.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
